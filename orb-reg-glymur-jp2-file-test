#Register offset jp.2 images with glymur and ORB

#Use glymur to manipulate .jp2 files - common file format for high resolution satellite images. 
#Read in one smaller image section from .jp2 image, find ORB keypoints. 
#Then read in two slightly offset and do ORB matching. 
#This program uses 'nemo' a 3-channel .jp2 file preloaded with glymur for testing. 

#Read in preloaded .jp2 file 'nemo' and slice to get crop and/or lower resolution version
import cv2, glymur, numpy as np
from matplotlib import pyplot as plt

jp2file=glymur.data.nemo()
jp3=glymur.Jp2k(jp2file)

#can use glymur to access .jp2 file structure to take get sections and/or lower resolution versions of the image
#full resolution
fullres=jp3[:]
print(fullres.shape)

#crop
crop=jp3[0:100:,0:100:]
print(crop.shape)

#first lower resolution
thumbnail=jp3[::2,::2]
print(thumbnail.shape)

#first lower resolution crop
thumbnailCrop=jp3[0:100:2,0:100:2]
print(thumbnailCrop.shape)

#break image into smaller (full res) tilesÂ¶
#split off some 500x500 images

crop00=jp3[0:500:,0:500:]
crop01=jp3[0:500:,500:1000:]
crop10=jp3[500:1000:,0:500:]
crop11=jp3[500:1000:,500:1000:]

#find and display ORB keypoints
cv2.imshow('00',crop00)
cv2.imshow('01',crop01)
cv2.imshow('10',crop10)
cv2.imshow('11',crop11)
k=cv2.waitKey(0)
cv2.destroyAllWindows()

orb=cv2.ORB_create()
kpI=orb.detect(crop00,None)
kpI,desI = orb.compute(crop00,kpI)

crop00Key=cv2.drawKeypoints(crop00,kpI,None,color=(0,255,0), flags=0)
plt.imshow(crop00Key),plt.show()

#Read in the cropped image directly rather than reading in full and then pulling out crop
jp2file=glymur.data.nemo()
cropped=glymur.Jp2k(jp2file)[0:100:2,0:100:2]
print(cropped.shape)

#ORB keypoint matching

#Make two closely overlapping files to try keypoint matching on
#make image files
cropA=jp3[0:500:,0:500:]
cropB=jp3[10:510:,10:510:]
#get ORB keypoints
orb=cv2.ORB_create()
kpI=orb.detect(cropA,None)
kpI,desI = orb.compute(cropA,kpI)
kpII=orb.detect(cropB,None)
kpII,desII = orb.compute(cropB,kpII)
#draw images with keypoints
cropAKey=cv2.drawKeypoints(cropA,kpI,None,color=(0,255,0), flags=0)
plt.imshow(cropAKey),plt.show()
cropBKey=cv2.drawKeypoints(cropB,kpI,None,color=(0,255,0), flags=0)
plt.imshow(cropBKey),plt.show()

# create BFMatcher object
bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
# Match descriptors.
matches = bf.match(desI,desII)
# Sort them in the order of their distance.
matches = sorted(matches, key = lambda x:x.distance)
# Draw first 10 matches.
img3 = cv2.drawMatches(cropA,kpI,cropB,kpII,matches[:10], None,flags=2)
plt.imshow(img3),plt.show()

print(len(matches))
matchesShort=matches[0:50]
print(len(matchesShort))
src_pts = np.float32([ kpI[m.queryIdx].pt for m in matchesShort ]).reshape(-1,1,2)
dst_pts = np.float32([ kpII[m.trainIdx].pt for m in matchesShort ]).reshape(-1,1,2)

M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)
matchesMask = mask.ravel().tolist()

h,w = cropA.shape[0:2]
pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)
dst = cv2.perspectiveTransform(pts,M)
print(dst)
cropBwBox = cv2.polylines(cropB,[np.int32(dst)],True,255,3, cv2.LINE_AA)
draw_params = dict(matchColor = (0,255,0), # draw matches in green color
                   singlePointColor = None,
                   matchesMask = matchesMask, # draw only inliers
                   flags = 2)

img3 = cv2.drawMatches(cropA,kpI,cropBwBox,kpII,matchesShort,None,**draw_params)

plt.imshow(img3, 'gray'),plt.show()
print(cropA.shape)
#show images overlayed

h1,w1=cropA.shape[0:2]
h2,w2=cropB.shape[0:2] 

y1=10
y2=500
x1=10
x2=500
roiI = cropA[y1:y2, x1:x2]
print(roiI.shape)

#cut off equivalent amounts from imgGrayCropII
y1=0
y2=490
x1=0
x2=490
roiII = cropB[y1:y2, x1:x2]
#plt.imshow(roiI,'gray'),plt.show()
print(roiII.shape)

#So now roiI and roiII are the same size and should be registered.

img=roiI
img2=roiI
img3=roiII

def nothing(x):
    pass

cv2.namedWindow('image')

#create trackbar for blending
cv2.createTrackbar('blend','image',0,100,nothing)

#create switch to switch between two images
switch = '0: img1 \n1 1: img2'
cv2.createTrackbar(switch, 'image',0,1,nothing)

while(1):
    cv2.imshow('image',img)
    k=cv2.waitKey(1) & 0xFF
    if k == 27:
        break

    #blending two images
    blend=cv2.getTrackbarPos('blend','image')
    dst=cv2.addWeighted(img2,blend/100,img3,(100-blend)/100,0)
    s=cv2.getTrackbarPos(switch,'image')
    
    if s==0:
        img=img2
    else:
        img=dst 
        #replace 'img=dst' with 'img=img3 here if you want to toggle between img2 and img3 instead of blending
cv2.destroyAllWindows()
